# CSCI E-103 Final Project â€“ Energy Prosumers Lakehouse  
### Group 1 â€“ Fall 2025

---

## ğŸ“˜ Project Overview

Our team was tasked with acting as consultants for a SaaS company aiming to build a **scalable data lakehouse** and a **machine learning prediction pipeline**.  
The use case is based on **Estonian energy prosumers** (customers who both consume and produce energy, often via solar panels).  

Our objectives were to:

1. **Ingest** raw Kaggle datasets into a governed Lakehouse  
2. **Apply multi-layer transformations** using the Medallion Architecture (Bronze â†’ Silver â†’ Gold)  
3. Build a **machine learning model** to help predict **electricity production and consumption**  
4. Deliver a **business intelligence dashboard** powered by curated Gold tables  
5. Provide architectural, modeling, and data governance documentation  

---

## ğŸ‘¥ Team Members & Roles

| Name      | Role(s) |
|-----------|---------|
| **Luke** | Data Engineer 1 |
| **Kenichi** | Data Engineer 2 |
| **Selin** | Data Scientist 1 |
| **Liwei** | Data Scientist 2 & BI Analyst 1 |
| **Peiran** | BI Analyst 2 |
| **Abby** | Data Architect 1 & Group Leader |
| **Chijioke** | Data Architect 2 |

---

# ğŸ—ï¸ Architecture Summary

We implemented a **Lakehouse** using Delta Lake with three layers:

### **BRONZE** â€“ Raw Delta tables created from CSVs  
### **SILVER** â€“ Cleaned, enriched, and (for weather data) **streamed**  
### **GOLD** â€“ Aggregated, business-ready tables for BI and ML  

Streaming was implemented for the Silver layer using Structured Streaming + `trigger(once=True)`.

---

# ğŸ“Š End-to-End Data Lineage Diagram  
*(Developed by Kenichi â€“ Data Engineer 2)*

This diagram shows how raw data flows from ingestion to BI outputs.

```text
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚     Raw CSV Files (Kaggle)    â”‚
                             â”‚  client.csv                   â”‚
                             â”‚  train.csv                    â”‚
                             â”‚  gas_prices.csv               â”‚
                             â”‚  electricity_prices.csv       â”‚
                             â”‚  historical_weather.csv        â”‚
                             â”‚  forecast_weather.csv          â”‚
                             â”‚  weather_station_mapping.csv   â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             |
                                             v
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚              BRONZE LAYER              â”‚
                          â”‚     (Raw, Ingested Delta Tables)       â”‚
                          â”‚-----------------------------------------â”‚
                          â”‚ bronze_client                          â”‚
                          â”‚ bronze_train                           â”‚
                          â”‚ bronze_gas_prices                      â”‚
                          â”‚ bronze_electricity_prices              â”‚
                          â”‚ bronze_weather_hist                    â”‚
                          â”‚ bronze_weather_forecast                â”‚
                          â”‚ bronze_weather_mapping                 â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          |
                                          v
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                      SILVER LAYER                        â”‚
                â”‚       (Cleaned, Enriched, **STREAMING** Version)        â”‚
                â”‚----------------------------------------------------------â”‚
                â”‚ Streaming read from:                                     â”‚
                â”‚   - bronze_weather_hist                                  â”‚
                â”‚   - bronze_weather_forecast                              â”‚
                â”‚ Join with static mapping table:                          â”‚
                â”‚   - bronze_weather_mapping (adds county)                 â”‚
                â”‚ Structured Streaming w/ trigger=once â†’                   â”‚
                â”‚   - silver_weather_hist_stream                           â”‚
                â”‚   - silver_weather_forecast_stream                       â”‚
                â”‚ Checkpoints stored in UC Volume                          â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                |
                                v
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                GOLD LAYER                               â”‚
        â”‚     (Business-level aggregates, upserts, optimized for BI queries)      â”‚
        â”‚-------------------------------------------------------------------------â”‚
        â”‚ gold_daily_energy_report                                                â”‚
        â”‚ - Combines county weather, pricing, and consumption                     â”‚
        â”‚ - Uses Delta MERGE for incremental updates                              â”‚
        â”‚ - OPTIMIZE + ZORDER BY (county, date)                                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            |
                            v
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   BI Dashboards + ML Workloads    â”‚
                   â”‚  (Consuming curated Gold tables)  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ§‘â€ğŸ’¼ Team Contributions

This section describes the contributions of each role in our group, aligned to the project requirements of CSCI E-103.

---

## ğŸ› ï¸ Data Engineering

### **Data Engineer 1 â€“ Luke**

Luke developed the foundational components of our Lakehouse pipeline:

#### âœ” Repository & Project Framework
- Created the GitHub repository and initial notebook structure  
- Established folder organization used throughout the project  

#### âœ” Bronze Layer Ingestion
Converted raw Kaggle CSVs into Delta tables, including:

- `bronze_client`  
- `bronze_train`  
- `bronze_gas_prices`  
- `bronze_electricity_prices`  
- `bronze_weather_hist`  
- `bronze_weather_forecast`  
- `bronze_weather_mapping`  

#### âœ” Batch Silver Layer  
- Joined weather data with county mapping  
- Produced initial Silver weather tables used by downstream consumers  

#### âœ” Gold Aggregation Layer (Batch)
Implemented the first Gold-level business table:

- Built `gold_daily_energy_report`  
- Performed daily aggregations  
- Added Delta **MERGE** logic for incremental updates  

**Lukeâ€™s work created the initial medallion pipeline upon which the rest of the system was built.**

---

### **Data Engineer 2 â€“ Kenichi**

Kenichi completed the remaining Data Engineering requirements and significantly enhanced reliability and performance.

#### ğŸ”¹ 1. Implemented Silver Structured Streaming Layer (`trigger=once`)
- Converted the Silver weather processing pipeline into a **Structured Streaming** job  
- Streaming inputs:  
  - `bronze_weather_hist`  
  - `bronze_weather_forecast`
- Joined with dimension table:  
  - `bronze_weather_mapping` (adds county)
- Outputs:
  - `silver_weather_hist_stream`  
  - `silver_weather_forecast_stream`
- Implemented checkpointing in UC Volume  
- Fully satisfies the DE rubric requirement for *incremental processing via streaming*  

#### ğŸ”¹ 2. Added Configuration + Data Quality Checks  
Strengthened pipeline quality by adding:

- Centralized catalog/schema/volume configuration  
- Table existence checks before streaming  
- Required column validation (lat/long/datetime)  
- Clear error surfacing to prevent silent failures  

#### ğŸ”¹ 3. Optimized Gold Layer Performance  
Added BI-focused optimization:

```sql
OPTIMIZE gold_daily_energy_report
ZORDER BY (county, date);
```
#### ğŸ”¹ 4. Created the End-to-End Data Lineage Diagram
- Authored a clear, intuitive lineage diagram (notebook: `00_data_lineage_diagram`)  
- Illustrates how data moves through the Medallion Architecture  
- Highlights where Structured Streaming occurs  
- Used as a visual anchor during the final presentation  

#### ğŸ”¹ 5. Added Data Engineering Helper Utilities
Developed reusable helper functions used by Data Engineering, Data Science, and BI:

- `table_info(table)` â€“ Row count, column count, schema  
- `compare_schemas(table1, table2)` â€“ Highlights differences between tables  
- `preview(table)` â€“ Displays first rows and schema  
- `validate_columns(table, expected_cols)` â€“ Checks for required columns  

These utilities speed up debugging, validation, and schema exploration across the team.

#### ğŸ”¹ 6. Pipeline Hardening & Documentation
- Added markdown explanations to notebooks  
- Ensured naming and configuration conventions were consistent  
- Improved maintainability and clarity of the DE pipeline  

---

## ğŸ¤– Data Science  
*(To be completed by Selin & Liwei)*

Expected content for this section:

- Exploratory Data Analysis (EDA)  
- Feature engineering  
- Model training (e.g., XGBoost, AutoML)  
- MLflow experiment tracking (parameters, metrics, artifacts)  
- Model evaluation methodology  
- Integration of predictions with Silver/Gold tables  

---

## ğŸ“Š Business Intelligence  
*(To be completed by Liwei & Peiran)*

Expected BI deliverables:

- SQL queries powering dashboards  
- Visualizations of daily usage, pricing, and production trends  
- Materialized views or refresh schedules  
- BI security model (California vs non-California access rules)  
- Dashboard layout and business insights  

---

## ğŸ›ï¸ Data Architecture  
*(To be completed by Abby & Chijioke)*

Expected content for this section:

- ERD with PK/FK relationships  
- Table cardinality & scale explanations  
- Partitioning & indexing strategy  
- CI/CD & deployment considerations  
- Disaster recovery planning  
- Extended enterprise architecture diagrams  

---

## ğŸ“ Repository Structure

final-project/
â”‚
â”œâ”€â”€ 00_data_lineage_diagram/ â† Lineage diagram (Kenichi)
â”œâ”€â”€ 00_helper_utilities/ â† Helper DE utilities (Kenichi)
â”œâ”€â”€ 01_ingest_bronze/ â† Bronze ingestion (Luke)
â”œâ”€â”€ 02_processing_silver/ â† Silver (batch) (Luke)
â”œâ”€â”€ 02A_processing_silver_streaming/ â† Silver (streaming) (Kenichi)
â”œâ”€â”€ 03_reporting_gold/ â† Gold aggregation + optimization
â””â”€â”€ README.md


---

## â–¶ï¸ Running the Pipeline

1. **Run `01_ingest_bronze`** to create Bronze Delta tables  
2. **Run either:**
   - `02_processing_silver` (batch)  
   - `02A_processing_silver_streaming` (streaming â€“ recommended)  
3. **Run `03_reporting_gold`** to generate Gold aggregates  
4. BI & ML workflows consume Gold tables as inputs  

---

## ğŸ“š References

- Databricks Delta Lake Documentation  
- CSCI E-103 Course Lectures & Labs  
- Kaggle: Estonian Energy Prosumers Dataset  

