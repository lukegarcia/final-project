# CSCI E-103 Final Project â€“ Energy Prosumers Lakehouse  
### Group 1 â€“ Fall 2025

---

## ğŸ“˜ Project Overview

Our team was tasked with acting as consultants for a SaaS company aiming to build a **scalable data lakehouse** and a **machine learning prediction pipeline**.  
The use case is based on **Estonian energy prosumers** (customers who both consume and produce energy, often via solar panels).  

Our objectives were to:

1. **Ingest** raw Kaggle datasets into a governed Lakehouse  
2. **Apply multi-layer transformations** using the Medallion Architecture (Bronze â†’ Silver â†’ Gold)  
3. Build a **machine learning model** to help predict **electricity production and consumption**  
4. Deliver a **business intelligence dashboard** powered by curated Gold tables  
5. Provide architectural, modeling, and data governance documentation  

---

## ğŸ‘¥ Team Members & Roles

| Name      | Role(s) |
|-----------|---------|
| **Luke** | Data Engineer 1 |
| **Kenichi** | Data Engineer 2 |
| **Selin** | Data Scientist 1 |
| **Liwei** | Data Scientist 2 & BI Analyst 1 |
| **Peiran** | BI Analyst 2 |
| **Abby** | Data Architect 1 & Group Leader |
| **Chijioke** | Data Architect 2 |

---

# ğŸ—ï¸ Architecture Summary

We implemented a **Lakehouse** using Delta Lake with three layers:

### **BRONZE** â€“ Raw Delta tables created from CSVs  
### **SILVER** â€“ Cleaned, enriched, and (for weather data) **streamed**  
### **GOLD** â€“ Aggregated, business-ready tables for BI and ML  

Streaming was implemented for the Silver layer using Structured Streaming + `trigger(once=True)`.

---

# ğŸ“Š End-to-End Data Lineage Diagram  
*(Developed by Kenichi â€“ Data Engineer 2)*

This diagram shows how raw data flows from ingestion to BI outputs.

```text
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚     Raw CSV Files (Kaggle)    â”‚
                             â”‚  client.csv                   â”‚
                             â”‚  train.csv                    â”‚
                             â”‚  gas_prices.csv               â”‚
                             â”‚  electricity_prices.csv       â”‚
                             â”‚  historical_weather.csv        â”‚
                             â”‚  forecast_weather.csv          â”‚
                             â”‚  weather_station_mapping.csv   â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             |
                                             v
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚              BRONZE LAYER              â”‚
                          â”‚     (Raw, Ingested Delta Tables)       â”‚
                          â”‚-----------------------------------------â”‚
                          â”‚ bronze_client                          â”‚
                          â”‚ bronze_train                           â”‚
                          â”‚ bronze_gas_prices                      â”‚
                          â”‚ bronze_electricity_prices              â”‚
                          â”‚ bronze_weather_hist                    â”‚
                          â”‚ bronze_weather_forecast                â”‚
                          â”‚ bronze_weather_mapping                 â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          |
                                          v
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                      SILVER LAYER                        â”‚
                â”‚       (Cleaned, Enriched, **STREAMING** Version)        â”‚
                â”‚----------------------------------------------------------â”‚
                â”‚ Streaming read from:                                     â”‚
                â”‚   - bronze_weather_hist                                  â”‚
                â”‚   - bronze_weather_forecast                              â”‚
                â”‚ Join with static mapping table:                          â”‚
                â”‚   - bronze_weather_mapping (adds county)                 â”‚
                â”‚ Structured Streaming w/ trigger=once â†’                   â”‚
                â”‚   - silver_weather_hist_stream                           â”‚
                â”‚   - silver_weather_forecast_stream                       â”‚
                â”‚ Checkpoints stored in UC Volume                          â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                |
                                v
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                GOLD LAYER                               â”‚
        â”‚     (Business-level aggregates, upserts, optimized for BI queries)      â”‚
        â”‚-------------------------------------------------------------------------â”‚
        â”‚ gold_daily_energy_report                                                â”‚
        â”‚ - Combines county weather, pricing, and consumption                     â”‚
        â”‚ - Uses Delta MERGE for incremental updates                              â”‚
        â”‚ - OPTIMIZE + ZORDER BY (county, date)                                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            |
                            v
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   BI Dashboards + ML Workloads    â”‚
                   â”‚  (Consuming curated Gold tables)  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ğŸ› ï¸ Data Engineering
Data Engineer 1 â€“ Luke

Luke built the foundation of the data pipeline, including:

âœ” GitHub Repository & Initial Notebook Framework

Created the group repository and structured the project

Provided the starting point for the lakehouse pipeline

âœ” Bronze Layer Ingestion

Ingested raw CSVs into Delta format using:

bronze_client

bronze_train

bronze_gas_prices

bronze_electricity_prices

bronze_weather_hist

bronze_weather_forecast

bronze_weather_mapping

âœ” Batch Silver Layer

Joined weather tables with county mapping

Produced initial Silver tables for downstream use

âœ” Gold Aggregations & MERGE Logic

Built gold_daily_energy_report with:

Daily aggregations

Pricing joins

Delta MERGE for incremental updates

Lukeâ€™s work established the compute-ready Lakehouse that the rest of the team built upon.

Data Engineer 2 â€“ Kenichi

Kenichi completed the remaining Data Engineering requirements and enhanced pipeline robustness, performance, and documentation.

ğŸ”¹ 1. Implemented Silver STRUCTURED STREAMING pipeline (trigger=once)

Converted Silver weather transformations into a streaming job

Used spark.readStream.table(...) for Bronze weather inputs

Joined with static mapping table

Wrote outputs to:

silver_weather_hist_stream

silver_weather_forecast_stream

Added checkpointing in Unity Catalog Volume

Fulfilled the DE rubric requirement for incremental streaming via trigger(once=True)

ğŸ”¹ 2. Added Data Quality Checks + Configuration Layer

Verified Bronze table existence

Checked for required columns (lat, long, datetime)

Centralized catalog, schema, and volume configuration

Improved maintainability and debugging for all teammates

ğŸ”¹ 3. Optimized the Gold Layer

Added BI performance tuning:

OPTIMIZE gold_daily_energy_report
ZORDER BY (county, date);

ğŸ”¹ 4. Created End-to-End Data Lineage Diagram

Produced a clean, intuitive pipeline diagram

Added 00_data_lineage_diagram notebook with documentation

Provided a key visual aid for the final presentation

ğŸ”¹ 5. Added Helper Utilities for the Team

Reusable functions such as:

table_info()

compare_schemas()

preview()

validate_columns()

These tools improved debugging, exploration, and development efficiency.

ğŸ”¹ 6. Documentation, Hardening & Cross-team Support

Improved notebook explanations

Added comments and markdown

Ensured consistency across pipeline layers

ğŸ¤– Data Science (to be completed by Selin & Liwei)

Examples of what will go here:

Data exploration & feature engineering

Model training (e.g., XGBoost, AutoML)

MLflow tracking: parameters, metrics, artifacts

Model evaluation and comparison

Serving predictions or saving Gold ML inference tables

(This section is a placeholder for DS teammates to complete.)

ğŸ“Š BI & Dashboarding (to be completed by Liwei & Peiran)

Examples expected here:

SQL queries used to build the dashboard

Visualizations created (line charts, bar charts, time-series views)

Role-based access model (California vs non-California groups)

Refresh schedule and materialized views

(This section is a placeholder for BI teammates to complete.)

ğŸ›ï¸ Data Architecture (to be completed by Abby & Chijioke)

This section should include:

ERD diagram with PK/FK relationships

Explanation of table cardinality & scale

Partitioning strategy

CI/CD considerations

Disaster recovery plan

Extended dataflow diagram (if applicable)

(This section is a placeholder for Data Architects to complete.)

ğŸ“ Repository Structure
final-project/
â”‚
â”œâ”€â”€ 00_data_lineage_diagram
â”œâ”€â”€ 00_helper_utilities
â”œâ”€â”€ 01_ingest_bronze
â”œâ”€â”€ 02_processing_silver
â”œâ”€â”€ 02A_processing_silver_streaming   â† (Kenichi)
â”œâ”€â”€ 03_reporting_gold
â””â”€â”€ README.md

â–¶ï¸ Running the Pipeline

Run 01_ingest_bronze to create Bronze Delta tables

Run 02_processing_silver OR 02A_processing_silver_streaming

Run 03_reporting_gold

BI dashboard queries pull from Gold tables

ML model consumes curated Silver/Gold features

ğŸ“š References

Databricks Delta Lake Documentation

CSCI E-103 Course Content

Kaggle Estonian Energy Prosumers Dataset
