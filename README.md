# CSCI E-103 Final Project â€“ Energy Prosumers Lakehouse  
### Group 1 â€“ Fall 2025

---

## ğŸ“˜ Project Overview

Our team was tasked with acting as consultants for a SaaS company aiming to build a **scalable data lakehouse** and a **machine learning prediction pipeline**.  
The use case is based on **Estonian energy prosumers** (customers who both consume and produce energy, often via solar panels).  

Our objectives were to:

1. **Ingest** raw Kaggle datasets into a governed Lakehouse  
2. **Apply multi-layer transformations** using the Medallion Architecture (Bronze â†’ Silver â†’ Gold)  
3. Build a **machine learning model** to help predict **electricity production and consumption**  
4. Deliver a **business intelligence dashboard** powered by curated Gold tables  
5. Provide architectural, modeling, and data governance documentation  

---

## ğŸ‘¥ Team Members & Roles

| Name      | Role(s) |
|-----------|---------|
| **Luke** | Data Engineer 1 |
| **Kenichi** | Data Engineer 2 |
| **Selin** | Data Scientist 1 |
| **Liwei** | Data Scientist 2 & BI Analyst 1 |
| **Peiran** | BI Analyst 2 |
| **Abby** | Data Architect 1 & Group Leader |
| **Chijioke** | Data Architect 2 |

---

# ğŸ—ï¸ Architecture Summary

We implemented a **Lakehouse** using Delta Lake with three layers:

### **BRONZE** â€“ Raw Delta tables created from CSVs  
### **SILVER** â€“ Cleaned, enriched, and (for weather data) **streamed**  
### **GOLD** â€“ Aggregated, business-ready tables for BI and ML  

Streaming was implemented for the Silver layer using Structured Streaming + `trigger(once=True)`.

---

# ğŸ“Š End-to-End Data Lineage Diagram  
*(Developed by Kenichi â€“ Data Engineer 2)*

This diagram shows how raw data flows from ingestion to BI outputs.

```text
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚     Raw CSV Files (Kaggle)    â”‚
                             â”‚  client.csv                   â”‚
                             â”‚  train.csv                    â”‚
                             â”‚  gas_prices.csv               â”‚
                             â”‚  electricity_prices.csv       â”‚
                             â”‚  historical_weather.csv        â”‚
                             â”‚  forecast_weather.csv          â”‚
                             â”‚  weather_station_mapping.csv   â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             |
                                             v
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚              BRONZE LAYER              â”‚
                          â”‚     (Raw, Ingested Delta Tables)       â”‚
                          â”‚-----------------------------------------â”‚
                          â”‚ bronze_client                          â”‚
                          â”‚ bronze_train                           â”‚
                          â”‚ bronze_gas_prices                      â”‚
                          â”‚ bronze_electricity_prices              â”‚
                          â”‚ bronze_weather_hist                    â”‚
                          â”‚ bronze_weather_forecast                â”‚
                          â”‚ bronze_weather_mapping                 â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          |
                                          v
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                      SILVER LAYER                        â”‚
                â”‚       (Cleaned, Enriched, **STREAMING** Version)        â”‚
                â”‚----------------------------------------------------------â”‚
                â”‚ Streaming read from:                                     â”‚
                â”‚   - bronze_weather_hist                                  â”‚
                â”‚   - bronze_weather_forecast                              â”‚
                â”‚ Join with static mapping table:                          â”‚
                â”‚   - bronze_weather_mapping (adds county)                 â”‚
                â”‚ Structured Streaming w/ trigger=once â†’                   â”‚
                â”‚   - silver_weather_hist_stream                           â”‚
                â”‚   - silver_weather_forecast_stream                       â”‚
                â”‚ Checkpoints stored in UC Volume                          â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                |
                                v
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                GOLD LAYER                               â”‚
        â”‚     (Business-level aggregates, upserts, optimized for BI queries)      â”‚
        â”‚-------------------------------------------------------------------------â”‚
        â”‚ gold_daily_energy_report                                                â”‚
        â”‚ - Combines county weather, pricing, and consumption                     â”‚
        â”‚ - Uses Delta MERGE for incremental updates                              â”‚
        â”‚ - OPTIMIZE + ZORDER BY (county, date)                                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            |
                            v
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   BI Dashboards + ML Workloads    â”‚
                   â”‚  (Consuming curated Gold tables)  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ§‘â€ğŸ’¼ Team Contributions

This section describes the contributions of each role in our group, aligned to the project requirements of CSCI E-103.

---

## ğŸ› ï¸ Data Engineering

### **Data Engineer 1 â€“ Luke**

Luke developed the foundational components of our Lakehouse pipeline:

#### âœ” Repository & Project Framework
- Created the GitHub repository and initial notebook structure  
- Established folder organization used throughout the project  

#### âœ” Bronze Layer Ingestion
Converted raw Kaggle CSVs into Delta tables, including:

- `bronze_client`  
- `bronze_train`  
- `bronze_gas_prices`  
- `bronze_electricity_prices`  
- `bronze_weather_hist`  
- `bronze_weather_forecast`  
- `bronze_weather_mapping`  

#### âœ” Batch Silver Layer  
- Joined weather data with county mapping  
- Produced initial Silver weather tables used by downstream consumers  

#### âœ” Gold Aggregation Layer (Batch)
Implemented the first Gold-level business table:

- Built `gold_daily_energy_report`  
- Performed daily aggregations  
- Added Delta **MERGE** logic for incremental updates  

**Lukeâ€™s work created the initial medallion pipeline upon which the rest of the system was built.**

---

### **Data Engineer 2 â€“ Kenichi**

Kenichi completed the remaining Data Engineering requirements and significantly enhanced reliability and performance.

#### ğŸ”¹ 1. Implemented Silver Structured Streaming Layer (`trigger=once`)
- Converted the Silver weather processing pipeline into a **Structured Streaming** job  
- Streaming inputs:  
  - `bronze_weather_hist`  
  - `bronze_weather_forecast`
- Joined with dimension table:  
  - `bronze_weather_mapping` (adds county)
- Outputs:
  - `silver_weather_hist_stream`  
  - `silver_weather_forecast_stream`
- Implemented checkpointing in UC Volume  
- Fully satisfies the DE rubric requirement for *incremental processing via streaming*  

#### ğŸ”¹ 2. Added Configuration + Data Quality Checks  
Strengthened pipeline quality by adding:

- Centralized catalog/schema/volume configuration  
- Table existence checks before streaming  
- Required column validation (lat/long/datetime)  
- Clear error surfacing to prevent silent failures  

#### ğŸ”¹ 3. Optimized Gold Layer Performance  
Added BI-focused optimization:

```sql
OPTIMIZE gold_daily_energy_report
ZORDER BY (county, date);



