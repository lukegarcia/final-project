# CSCI E-103 Final Project â€“ Energy Prosumers Lakehouse  
### Group 1 â€“ Fall 2025

---

## ğŸ“˜ Project Overview

Our team was tasked with acting as consultants for a SaaS company aiming to build a **scalable data lakehouse** and a **machine learning prediction pipeline**.  
The use case is based on **Estonian energy prosumers** (customers who both consume and produce energy, often via solar panels).  

Our objectives were to:

1. **Ingest** raw Kaggle datasets into a governed Lakehouse  
2. **Apply multi-layer transformations** using the Medallion Architecture (Bronze â†’ Silver â†’ Gold)  
3. Build a **machine learning model** to help predict **electricity production and consumption**  
4. Deliver a **business intelligence dashboard** powered by curated Gold tables  
5. Provide architectural, modeling, and data governance documentation  

---

## ğŸ‘¥ Team Members & Roles

| Name      | Role(s) |
|-----------|---------|
| **Luke** | Data Engineer 1 |
| **Kenichi** | Data Engineer 2 |
| **Selin** | Data Scientist 1 |
| **Liwei** | Data Scientist 2 & BI Analyst 1 |
| **Peiran** | BI Analyst 2 |
| **Abby** | Data Architect 1 & Group Leader |
| **Chijioke** | Data Architect 2 |

---

# ğŸ—ï¸ Architecture Summary

We implemented a **Lakehouse** using Delta Lake with three layers:

### **BRONZE** â€“ Raw Delta tables created from CSVs  
### **SILVER** â€“ Cleaned, enriched, and (for weather data) **streamed**  
### **GOLD** â€“ Aggregated, business-ready tables for BI and ML  

Streaming was implemented for the Silver layer using Structured Streaming + `trigger(once=True)`.

---

# ğŸ“Š End-to-End Data Lineage Diagram  
*(Developed by Kenichi â€“ Data Engineer 2)*

This diagram shows how raw data flows from ingestion to BI outputs.

```text
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚     Raw CSV Files (Kaggle)    â”‚
                             â”‚  client.csv                   â”‚
                             â”‚  train.csv                    â”‚
                             â”‚  gas_prices.csv               â”‚
                             â”‚  electricity_prices.csv       â”‚
                             â”‚  historical_weather.csv        â”‚
                             â”‚  forecast_weather.csv          â”‚
                             â”‚  weather_station_mapping.csv   â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             |
                                             v
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚              BRONZE LAYER              â”‚
                          â”‚     (Raw, Ingested Delta Tables)       â”‚
                          â”‚-----------------------------------------â”‚
                          â”‚ bronze_client                          â”‚
                          â”‚ bronze_train                           â”‚
                          â”‚ bronze_gas_prices                      â”‚
                          â”‚ bronze_electricity_prices              â”‚
                          â”‚ bronze_weather_hist                    â”‚
                          â”‚ bronze_weather_forecast                â”‚
                          â”‚ bronze_weather_mapping                 â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          |
                                          v
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                      SILVER LAYER                        â”‚
                â”‚       (Cleaned, Enriched, **STREAMING** Version)        â”‚
                â”‚----------------------------------------------------------â”‚
                â”‚ Streaming read from:                                     â”‚
                â”‚   - bronze_weather_hist                                  â”‚
                â”‚   - bronze_weather_forecast                              â”‚
                â”‚ Join with static mapping table:                          â”‚
                â”‚   - bronze_weather_mapping (adds county)                 â”‚
                â”‚ Structured Streaming w/ trigger=once â†’                   â”‚
                â”‚   - silver_weather_hist_stream                           â”‚
                â”‚   - silver_weather_forecast_stream                       â”‚
                â”‚ Checkpoints stored in UC Volume                          â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                |
                                v
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                GOLD LAYER                               â”‚
        â”‚     (Business-level aggregates, upserts, optimized for BI queries)      â”‚
        â”‚-------------------------------------------------------------------------â”‚
        â”‚ gold_daily_energy_report                                                â”‚
        â”‚ - Combines county weather, pricing, and consumption                     â”‚
        â”‚ - Uses Delta MERGE for incremental updates                              â”‚
        â”‚ - OPTIMIZE + ZORDER BY (county, date)                                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            |
                            v
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   BI Dashboards + ML Workloads    â”‚
                   â”‚  (Consuming curated Gold tables)  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ§‘â€ğŸ’¼ Team Contributions

This section describes the contributions of each role in our group, aligned to the project requirements of CSCI E-103.

---

## ğŸ› ï¸ Data Engineering

### **Data Engineer 1 â€“ Luke**

Luke developed the foundational components of our Lakehouse pipeline:

#### âœ” Repository & Project Framework
- Created the GitHub repository and initial notebook structure  
- Established folder organization used throughout the project  

#### âœ” Bronze Layer Ingestion
Converted raw Kaggle CSVs into Delta tables, including:

- `bronze_client`  
- `bronze_train`  
- `bronze_gas_prices`  
- `bronze_electricity_prices`  
- `bronze_weather_hist`  
- `bronze_weather_forecast`  
- `bronze_weather_mapping`  

#### âœ” Batch Silver Layer  
- Joined weather data with county mapping  
- Produced initial Silver weather tables used by downstream consumers  

#### âœ” Gold Aggregation Layer (Batch)
Implemented the first Gold-level business table:

- Built `gold_daily_energy_report`  
- Performed daily aggregations  
- Added Delta **MERGE** logic for incremental updates  

**Lukeâ€™s work created the initial medallion pipeline upon which the rest of the system was built.**

---

### **Data Engineer 2 â€“ Kenichi**

Kenichi completed the remaining Data Engineering requirements and significantly enhanced reliability and performance.

#### ğŸ”¹ 1. Implemented Silver Structured Streaming Layer (`trigger=once`)
- Converted the Silver weather processing pipeline into a **Structured Streaming** job  
- Streaming inputs:  
  - `bronze_weather_hist`  
  - `bronze_weather_forecast`
- Joined with dimension table:  
  - `bronze_weather_mapping` (adds county)
- Outputs:
  - `silver_weather_hist_stream`  
  - `silver_weather_forecast_stream`
- Implemented checkpointing in UC Volume  
- Fully satisfies the DE rubric requirement for *incremental processing via streaming*  

#### ğŸ”¹ 2. Added Configuration + Data Quality Checks  
Strengthened pipeline quality by adding:

- Centralized catalog/schema/volume configuration  
- Table existence checks before streaming  
- Required column validation (lat/long/datetime)  
- Clear error surfacing to prevent silent failures  

#### ğŸ”¹ 3. Optimized Gold Layer Performance  
Added BI-focused optimization:

```sql
OPTIMIZE gold_daily_energy_report
ZORDER BY (county, date);
```
#### ğŸ”¹ 4. Created the End-to-End Data Lineage Diagram
- Authored a clear, intuitive lineage diagram (notebook: `00_data_lineage_diagram`)  
- Illustrates how data moves through the Medallion Architecture  
- Highlights where Structured Streaming occurs  
- Used as a visual anchor during the final presentation  

#### ğŸ”¹ 5. Added Data Engineering Helper Utilities
Developed reusable helper functions used by Data Engineering, Data Science, and BI:

- `table_info(table)` â€“ Row count, column count, schema  
- `compare_schemas(table1, table2)` â€“ Highlights differences between tables  
- `preview(table)` â€“ Displays first rows and schema  
- `validate_columns(table, expected_cols)` â€“ Checks for required columns  

These utilities speed up debugging, validation, and schema exploration across the team.

#### ğŸ”¹ 6. Pipeline Hardening & Documentation
- Added markdown explanations to notebooks  
- Ensured naming and configuration conventions were consistent  
- Improved maintainability and clarity of the DE pipeline  

---

## ğŸ¤– Data Science  
*(To be completed by Selin & Liwei)*

Expected content for this section:

- Exploratory Data Analysis (EDA)  
- Feature engineering  
- Model training (e.g., XGBoost, AutoML)  
- MLflow experiment tracking (parameters, metrics, artifacts)  
- Model evaluation methodology  
- Integration of predictions with Silver/Gold tables  

---

## ğŸ“Š Business Intelligence  
*(To be completed by Liwei & Peiran)*

Expected BI deliverables:

- SQL queries powering dashboards  
- Visualizations of daily usage, pricing, and production trends  
- Materialized views or refresh schedules  
- BI security model (California vs non-California access rules)  
- Dashboard layout and business insights  

---

## ğŸ›ï¸ Data Architecture  
*(To be completed by Abby & Chijioke)*

Expected content for this section:

- ERD with PK/FK relationships  
- Table cardinality & scale explanations  
- Partitioning & indexing strategy  
- CI/CD & deployment considerations  
- Disaster recovery planning  
- Extended enterprise architecture diagrams
-                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚        DIM: client            â”‚
                             â”‚  (bronze_client / silver)     â”‚
                             â”‚-------------------------------â”‚
                             â”‚ PK: client_id (logical)       â”‚
                             â”‚ attrs: segment, region, ...   â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚ (optional join by client_id)
                                             â”‚
                                             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FACT: energy_targets (train)                               â”‚
â”‚                (bronze_train / silver_train)                                 â”‚
â”‚------------------------------------------------------------------------------â”‚
â”‚ Grain: 1 row per (datetime, county, is_consumption, is_business, product_typeâ”‚
â”‚        [and other categorical flags])                                         â”‚
â”‚------------------------------------------------------------------------------â”‚
â”‚ PK (logical): (datetime, county, is_consumption, is_business, product_type)  â”‚
â”‚ Measures: target (kWh), etc.                                                 â”‚
â”‚ Time keys: datetime (timestamp), date (derived)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ (temporal alignment by date/datetime)
                                â”‚
                                v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 FACT: electricity_prices (time-series)                        â”‚
â”‚                 (bronze_electricity_prices / silver optional)                 â”‚
â”‚------------------------------------------------------------------------------â”‚
â”‚ Grain: 1 row per datetime (or date)                                           â”‚
â”‚ Key (logical): datetime/date                                                  â”‚
â”‚ Measures: price                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FACT: gas_prices (time-series)                              â”‚
â”‚                   (bronze_gas_prices / silver optional)                       â”‚
â”‚------------------------------------------------------------------------------â”‚
â”‚ Grain: 1 row per datetime (or date)                                           â”‚
â”‚ Key (logical): datetime/date                                                  â”‚
â”‚ Measures: price                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚  DIM: weather_station_map         â”‚
                             â”‚ (bronze_weather_station_map)      â”‚
                             â”‚----------------------------------â”‚
                             â”‚ Key (logical): (latitude,longitude)â”‚
                             â”‚ attrs: county_name (and/or county) â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚ (geo enrichment join)
                                             â”‚ lat/lon join in Silver
                                             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FACT: weather_hist (observed)                                â”‚
â”‚      (bronze_historical_weather â†’ silver_weather_hist)                        â”‚
â”‚------------------------------------------------------------------------------â”‚
â”‚ Grain: 1 row per (latitude, longitude, datetime)                              â”‚
â”‚ PK (logical): (latitude, longitude, datetime)                                 â”‚
â”‚ Measures: temperature, dewpoint, rain, snowfall, windspeed, cloudcover, ...   â”‚
â”‚ Enriched attrs (Silver): county_name (from station_map)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FACT: weather_forecast (predicted)                           â”‚
â”‚      (bronze_forecast_weather â†’ silver_weather_forecast)                      â”‚
â”‚------------------------------------------------------------------------------â”‚
â”‚ Grain: 1 row per (latitude, longitude, forecast_datetime, hours_ahead)        â”‚
â”‚ PK (logical): (latitude, longitude, forecast_datetime, hours_ahead)           â”‚
â”‚ Measures: temperature, dewpoint, precipitation, radiation, wind components... â”‚
â”‚ Enriched attrs (Silver): county_name (from station_map)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚               GOLD LAYER                 â”‚
                                  â”‚------------------------------------------â”‚
                                  â”‚ gold_daily_energy_report (or equivalents)â”‚
                                  â”‚ Grain: 1 row per (county/date)           â”‚
                                  â”‚ Inputs: silver_train + silver_weather_*  â”‚
                                  â”‚         + prices (optional)              â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


---

## ğŸ“ Repository Structure

```text
final-project/
â”‚
â”œâ”€â”€ 00_data_lineage_diagram/          â† Lineage diagram notebook (Kenichi)
â”œâ”€â”€ 00_helper_utilities/              â† Helper DE utilities (Kenichi)
â”‚
â”œâ”€â”€ 01_ingest_bronze/                 â† Bronze ingestion (Luke)
â”œâ”€â”€ 02_processing_silver/             â† Silver batch (Luke)
â”œâ”€â”€ 02A_processing_silver_streaming/  â† Silver streaming (Kenichi)
â”‚
â”œâ”€â”€ 03_reporting_gold/                â† Gold aggregation + optimization
â””â”€â”€ README.md
```

ğŸ›ï¸ Data Architecture

(Completed by Abby & Chijioke)

This section documents the architectural design decisions that support scalability, governance, and analytics readiness across the Lakehouse.

ğŸ”¹ 1. Logical Data Model & ERD Design

The Lakehouse is centered around time-series fact tables enriched by geographic and client dimensions.

Fact tables

Energy consumption & production (train)

Historical and forecast weather (hourly granularity)

Electricity and gas pricing

Dimension tables

Client metadata

Weather station â†’ county mapping

Relationships are applied logically in the Silver layer through joins rather than enforced foreign-key constraints, aligning with Delta Lake and Lakehouse best practices.

ğŸ”¹ 2. Table Cardinality & Data Scale Validation

Architectural decisions were validated against real data volumes:

High-cardinality tables

bronze_train / silver_train: ~2M+ records

bronze_historical_weather / silver_weather_hist: ~1.7M+ records

Medium-cardinality tables

Electricity and gas prices (time-series)

Low-cardinality tables

Client and county mapping dimensions

This informed partitioning, deduplication, and aggregation strategies used downstream.

ğŸ”¹ 3. Partitioning & Optimization Strategy

Bronze Layer

Minimal transformation

No aggressive partitioning to preserve raw data fidelity

Silver Layer

Date-derived columns added for time-based processing

Deduplication enforced on natural keys (location + timestamp)

Streaming Silver tables leverage checkpointing for incremental ingestion

Gold Layer

Business-level aggregates optimized for BI

OPTIMIZE and ZORDER BY (county, date) applied for query performance

ğŸ”¹ 4. Deployment & Pipeline Reusability

The architecture supports re-runnable and production-aligned workflows:

Fully qualified catalog and schema references

Idempotent table creation using managed Delta tables

Layered notebook structure (Bronze â†’ Silver â†’ Gold)

Clear separation of batch and streaming responsibilities

This design is compatible with future Databricks Jobs or CI/CD automation.

ğŸ”¹ 5. Data Reliability & Recovery

Delta Lake provides ACID guarantees, schema enforcement, and versioning

Bronze tables serve as immutable recovery sources

Silver and Gold layers are fully reproducible from Bronze

Streaming checkpoints ensure exactly-once processing semantics

ğŸ”¹ 6. Enterprise Architecture Alignment

The Lakehouse supports:

Batch ingestion of raw source data

Incremental processing via Structured Streaming

Curated Gold tables for BI dashboards and ML workloads

Governed schemas for lineage, discoverability, and reuse

This positions the platform as a scalable analytics foundation beyond the course use case.

ğŸ”¹ Data Architect Contributions (Chijioke John Ifedili)

Validated Bronze-layer schema integrity and temporal coverage

Ensured Silver-layer join compatibility and enrichment readiness

Reviewed table scale, partitioning, and optimization strategies

Aligned Lakehouse design with enterprise data architecture principles

This work ensured the system was governed, scalable, and analytics-ready.

---

## â–¶ï¸ Running the Pipeline

1. **Run `01_ingest_bronze`** to create Bronze Delta tables  
2. **Run either:**
   - `02_processing_silver` (batch)  
   - `02A_processing_silver_streaming` (streaming â€“ recommended)  
3. **Run `03_reporting_gold`** to generate Gold aggregates  
4. BI & ML workflows consume Gold tables as inputs  

---

## ğŸ“š References

- Databricks Delta Lake Documentation  
- CSCI E-103 Course Lectures & Labs  
- Kaggle: Estonian Energy Prosumers Dataset  

